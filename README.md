# Web Scrapping and EDA
 
# Introduction
Imagine you have to pull a large amount of data from internet as quickly as possible, instead of manually saving the data from websites, the web scraping software will automatically load and extract data from multiple websites as per your requirement.

Web scraping, also called web data mining or web harvesting, is the process of constructing an agent which can extract, parse, download and organize useful information from the web automatically

# Uses of Web Scraping

The uses and reasons for using web scraping are as endless as the uses of the World Wide Web. Web scrapers can do anything like ordering online food, scanning online shopping website for you and buying ticket of a match the moment they are available etc. just like a human can do. 

# Some of the important uses of web scraping are discussed here −

+	E-commerce Websites − Web scrapers can collect the data specially related to the price of a specific product from various e-commerce websites for their comparison.

+	Content Aggregators − Web scraping is used widely by content aggregators like news aggregators and job aggregators for providing updated data to their users.

+	Marketing and Sales Campaigns − Web scrapers can be used to get the data like emails, phone number etc. for sales and marketing campaigns.

+	Search Engine Optimization (SEO) − Web scraping is widely used by SEO tools like SEMRush, Majestic etc. to tell business how they rank for search keywords that matter to them.

+	Data for Machine Learning Projects − Retrieval of data for machine learning projects depends upon web scraping.

+ Data for Research − Researchers can collect useful data for the purpose of their research work by saving their time by this automated process.


# Python Libraries for Web Scraping

**Requests:**

It is a simple python web scraping library. It is an efficient HTTP library used for accessing web pages. With the help of Requests, we can get the raw HTML of web pages which can then be parsed for retrieving the data.

**Urllib3:**
It is another Python library that can be used for retrieving data from URLs similar to the requests library. 

**Beautiful Soup:**

 BeautifulSoup is a Python library for pulling data out of HTML and XML files. It can be used with requests, because it needs an input (document or url) to create a soup object as it cannot fetch a web page by itself
 
**Selenium:** 
 Selenium is a web testing library. It is used to automate browser activities.
 
#  Steps in web scrabing
 
1. Find the URL that you want to scrape
2. Inspect Your Data Source
3. Find the data you want to extract
4. Scrape HTML Content From a Page
5. Parse HTML Code With Beautiful Soup
6. Extract the needed data from the HTML
7. Save the data as required
